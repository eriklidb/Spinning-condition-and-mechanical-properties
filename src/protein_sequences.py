import pandas as pd
import torch
from transformers.models.auto.modeling_auto import AutoModel
from transformers.models.auto.tokenization_auto import AutoTokenizer
from tqdm import tqdm
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import os
import numpy as np

class EmbeddingGenerator():
    def __init__(self, MODEL_NAME: str) -> None:
        self._sequences = pd.Series()
        self._sequences['NT'] = 'MGHHHHHHSHTTPWTNPGLAENFMNSFMQGLSSMPGFTASQLDDMSTIAQSMVQSIQSLAAQGRTSPNKLQALNMAFASSMAEIAASEEGGGSLSTKTSSIASAMSNAFLQTTGVVNQPFINEITQLVSMFAQAGMNDVSA'
        self._sequences['CT'] = 'VTSGGYGYGTSAAAGAGVAAGSYAGAVNRLSSAEAASRVSSNIAAIASGGASALPSVISNIYSGVVASGVSSNEALIQALLELLSALVHVLSSASIGNVSSVGVDSTLNVVQDSVGQYVG'
        self._sequences['NT-CT'] = self._sequences['NT'] + self._sequences['CT']
        self._sequences['NT2RepCT'] = 'MGHHHHHHMSHTTPWTNPGLAENFMNSFMQGLSSMPGFTASQLDDMSTIAQSMVQSIQSLAAQGRTSPNKLQALNMAFASSMAEIAASEEGGGSLSTKTSSIASAMSNAFLQTTGVVNQPFINEITQLVSMFAQAGMNDVSAGNSGRGQGGYGQGSGGNAAAAAAAAAAAAAAAGQGGQGGYGRQSQGAGSAAAAAAAAAAAAAAGSGQGGYGGQGQGGYGQSGSVTSGGYGYGTSAAAGAGVAAGSYAGAVNRLSSAEAASRVSSNIAAIASGGASALPSVISNIYSGVVASGVSSNEALIQALLELLSALVHVLSSASIGNVSSVGVDSTLNVVQDSVGQYVG'
        self._sequences['A3IA'] = 'MGHHHHHHMSHTTPWTNPGLAENFMNSFMQGLSSMPGFTASQLDDMSTIAQSMVQSIQSLAAQGRTSPNKLQALNMAFASSMAEIAASEEGGGSLSTKTSSIASAMSNAFLQTTGVVNQPFINEITQLVSMFAQAGMNDVSAGNSGRGQGGYGQGSGGNAAAIAAAIAAIAAAAGQGGQGGYGRQSQGAGSAAAAAAAAAAAAAAGSGQGGYGGQGQGGYGQSGSVTSGGYGYGTSAAAGAGVAAGSYAGAVNRLSSAEAASRVSSNIAAIASGGASALPSVISNIYSGVVASGVSSNEALIQALLELLSALVHVLSSASIGNVSSVGVDSTLNVVQDSVGQYVG'
        self._sequences['Rep1'] = self._sequences['NT'] + 'GNSGPGPQGPSGPGPQGPYGPGPQGPGPQGPAPQGPSGPGPQRPQGPGPQRPYGPGGISVVSTTVSGPGPQGPSAPGPQGPYGPGPQVPGPQGPGPQGPSGPGPQRPQGPGPQGPYGPGGVSVVSQTVSGPGPQGPSGPGPQGPYGPGPQGPGPQGPGPQGPSGAGPQRPQGPGPQGPSGS' + self._sequences['CT']
        self._sequences['Rep2'] = self._sequences['NT'] + 'GNSGRPSSSYGAPGGGNGGRPSDTYGAPGGGNGGRPSDTYGAPGGGGNGNGGRPSSSYGAPGQGQGNGNGGRPSSSYGAPGGGNGGRPSDTYGAPGGGNGGRPSDTYGAPGGGNNGGRPSSSYGAPGGGNGGRPSDTYGAPGGGNSGS' + self._sequences['CT']
        self._sequences['Rep3'] = self._sequences['NT'] + 'GNSGGAGVPGVPGAIPGIGGIAGVGTPAAAAAAAAAAKAAKYGAAAGLVPGGPGFGPGVVGVPGAGVPGVGVPGAGIPVVPGAGIPGAAVPGVVSPEAAAKAAAKAAKYGARPGVGVGGSGS' + self._sequences['CT']
        self._sequences['Rep4'] = self._sequences['NT'] + 'GNSGAAGKAGYPTGTGVGPQAAAAAAAKAAAKFGAGAAGVLPGVGGAGVPGVPGAIPGIGGIAGVGTPAAAAAAAAAAKAAKYGAAAGLVPGGPGFGPGVVGVPGAGVPGVGVPGAGIPVVPGAGIPGAAVPGVVSPEAAAKAAAKAAKYGARPGVGVGGIPTYGVGAGGFPGFGVGVGGIPGVAGVPSVGGVPGVGGVPGVGISPEAQAAAAAKAAKYGVGTPSGS' + self._sequences['CT']
        self._sequences['Rep5'] = self._sequences['NT'] + 'GNSGRGQGGYGQGSGGNAAAAAAAAAAAAAAAGAGAAGVLPGVGGAGVPGVPGAIPGIGGIAGVGTPAAAAAAAAAAAAAAGAGAAGVLPGVGGAGVPGVPGAIPGIGGIAGVGTPSVTSGGYGYGTSAAAGAGVAAGSYAGAVNRLSSAEAASGS' + self._sequences['CT']
        self._sequences['Rep6'] = self._sequences['NT'] + 'GNSSSSTTTTTIAARSQAASQSASSSYSSAFAQAASSSFATSSALSRAFSSVSSASAASSLAYSIGLSAARSLGIADAAGLAGALARAVGALGQGATAASYGNALSTAAGQFFATAGLLNAGNASALASSFARAFSASAESQSFAQSQAFQQASAFQQAASRSASQSAAEADSTSSSTTTTTSAARSQAASQSASSSYSSAFAQAASSSFATSSALSRAFSSVSSASAASSLAYSIGLSAARSLGIADAAGLAGALARAVGALGQGATAASYGNALSTAAGQFFATAGLLNAGNASALASSFARAFSASAESQSFAQSQAFQQASAFQQAASRSASQSAAEADSTSSSGS' + self._sequences['CT']
        self._sequences['Rep7'] = self._sequences['NT'] + 'GNSSSSTTTTTSAARSQAASQSASSSYSSAFAQAASSSFATSSALSRAFSSVSSASAASSLAYSIGLSAARSLGIADAAGLAGALARAVGALGQGATAASYGNALSTAAGQFFATAGLLNAGNASALASSFARAFSASAESQSFAQSQAFQQASAFQQAASRSASQSAAEADSTSSSGS' + self._sequences['CT']
        self._sequences['Rep8'] = self._sequences['NT'] + 'GNSGGSGPGGAGPGGAGPGGAGPGGAGPGGVGLGGAGRGGAGRGGAGSVGAGRGGAGRGGAGRGGAGRGGAGRGGAGGAGGAGGAGGPGGAGGSGGTTVIEDLDITIDGADGPITISEELTISGAGGSGPGGAGTGGVGPGGSGPGGVGPGGFGPGGVGPGGSGPGGVGPGGAGRPYGPGGSGPGGAGGAGGTGGAYGPGGAYGPGGSGGPGGAGGPGGEGPGGAGGPYGPGGAGSGS' + self._sequences['CT']
        self._sequences['Rep9'] = self._sequences['NT'] + 'GNSGGAGVPGVPGAIPGIGGIAGVGTPAAAAAAAAAAKAAKYGAAAGLVPGGPGFGPGVVGVPGAGVPGVGVPGAGIPVVPGAGIPGAAVPGVVSPEAAAKAAAKAAKYGARPGVGVGGSGS' + self._sequences['CT']
        self._sequences['Rep10'] = self._sequences['NT'] + 'GNSGAGAGGAGGYAQGYGAGAGAGAGAGTGAGGAGGYGQGYGAGSGAGAGGAGGYGAGAGAGAGAGGASGYGQGYGDGAGAGAGAAAAAGAAAGARGAGGYGGGAGDGAGAGAGAGAAGGYGQGYGAGEGAGAGAGAGGAGGYGAGAGAGGAGGYGQSYGDGAAAAAGSGAGAGGSGGYGAGAGAGAGAGAGSGAGAAGGYGGGAGAGVSGS' + self._sequences['CT']
        self._sequences['Rep11'] = self._sequences['NT'] + 'GNSSGAGAGGAGGYGGGAGAGADAGAGGAGGYGGGAGAGAGARAGAGGVGGYGQSYGAGAGAGAGVGAGGAGAGGADGYGQGYGAGAGTGAGDAGGYGGGAGAGASAGAGGYGGGAGAGGVGVYGKGYGSGSGAGAAAAAGAGGATGNRAGDAFAQVFSQNVINSGVITSTTVTKNSAQAAASSMVSTAAKSLGLDENTARSMANAMSSYAAAMAKSFRNSDEFIRNMSYQMGRMLSNAGAINESTASAAASSASSTVTETVRTYGPAAIFSGAGAGGAGGYAQGYGAGAGAGAGAGTGAGGAGGYGQGYGAGSGAGAGGAGGYGAGAGAGAGAGDASGYGQGYGDGAGAGAGAAAAAGAAAGARGAGGYSGS' + self._sequences['CT']
        self._sequences['Rep12'] = self._sequences['NT'] + 'GNSGPGPQGPSGPGPQGPYGPGPQGPGPQGPAPQGPSGPGPQRPQGPGPQRPYGPGGISVVSTTVGPGPQGPSAPGPQGPYGPGPQVPGPQGPGPQGPSGPGPQRPQGPGPQGPYGPGGVSVVSQTVSGS' + self._sequences['CT']
        self._sequences['Rep13'] = self._sequences['NT'] + 'GNSGPGPQGPLGPGAQVPYGPGPQVPGPQGPGPQGPSGPGPQRPQGPGPQGPYGPGGVSVVSQTVSGPGPQGPSGPGPQGPYGPGPQGPGPQGPAPQGPSGPGPQRPQGPGPQRPYGPGGISVVSTTVSGPGPQGPSAPGPQGPYGPGPQVPGPQGPGPQGPSGPGPQRPQGPGPQGPYGPGGVSVVSQTVSGPGPQGPSGPGPQGPYGPGPQGPGPQGPGPQGPSGAGPQRPQGPGPQGPYGPGGVSVVSATVSGS   and then ends with CT, which is VTSGGYGYGTSAAAGAGVAAGSYAGAVNRLSSAEAASRVSSNIAAIASGGASALPSVISNIYSGVVASGVSSNEALIQALLELLSALVHVLSSASIGNVSSVGVDSTLNVVQDSVGQYVG' + self._sequences['CT']
        self._sequences['4A 2rep'] = self._sequences['NT'] + 'GRGQGGYGQGSGGNAAAAGQGGQGGYGRQSQGAGSAAAAGSGQGGYGGQGQGGYGQ' + self._sequences['CT']
        self._sequences['VN-NT'] = 'MGHHHHHHMENLYFQGGPNSPQVTRGDVFTMPHMSHTTPWTNPGLAENFMNSFMQGLSSMPGFTASQLDDMSTIAQSMVQSIQSLAAQGRTSPNKLQALNMAFASSMAEIAASEEGGGSLSTKTSSIASAMSNAFLQTTGVVNQPFINEITQLVSMFAQAGMNDVSAGNS'
        self._sequences['VN-A3IA'] = 'MGHHHHHHMENLYFQGGPNSPQVTRGDVFTMPHMSHTTPWTNPGLAENFMNSFMQGLSSMPGFTASQLDDMSTIAQSMVQSIQSLAAQGRTSPNKLQALNMAFASSMAEIAASEEGGGSLSTKTSSIASAMSNAFLQTTGVVNQPFINEITQLVSMFAQAGMNDVSAGNSGRGQGGYGQGSGGNAAAIAAAIAAAIAAAGQGGQGGYGRQSQGAGSAAAAAAAAAAAAAAGSGQGGYGGQGQGGYGQSGSVTSGGYGYGTSAAAGAGVAAGSYAGAVNRLSSAEAASRVSSNIAAIASGGASALPSVISNIYSGVVASGVSSNEALIQALLELLSALVHVLSSASIGNVSSVGVDSTLNVVQDSVGQYVG'
        self._sequences['IdeS-A3IA'] = 'MGHHHHHHMSHTTPWTNPGLAENFMNSFMQGLSSMPGFTASQLDDMSTIAQSMVQSIQSLAAQGRTSPNKLQALNMAFASSMAEIAASEEGGGSLSTKTSSIASAMSNAFLQTTGVVNQPFINEITQLVSMFAQAGMNDVSAGNSGRGQGGYGQGSGGNAAAIAAAIAAAIAAAGQGGQGGYGRQSQGAGSAAAAAAAAAAAAAAGSGQGGYGGQGQGGYGQSGSVTSGGYGYGTSAAAGAGVAAGSYAGAVNRLSSAEAASRVSSNIAAIASGGASALPSVISNIYSGVVASGVSSNEALIQALLELLSALVHVLSSASIGNVSSVGVDSTLNVVQDSVGQYVGKLGSGSGSGSDSFSANQEIRYSEVTPYHVTSVWTKGVTPPAKFTQGEDVFHAPYVANQGWYDITKTFNGKDDLLCGAATAGNMLHWWFDQNKEKIEAYLKKHPDKQKIMFGDQELLDVRKVINTKGDQTNSELFNYFRDKAFPGLSARRIGVMPDLVLDMFINGYYLNVYKTQTTDVNRTYQEKDRRGGIFDAVFTRGDQSKLLTSRHDFKEKNLKEISDLIKKELTEGKALGLSHTYANVRINHVINLWGADFDSNGNLKAIYVTDSDSNASIGMKKYFVGVNSAGKVAISAKEIKEDNIGAQVLGLFTLSTGQDSWNQTN'
        self._sequences['fNT A3IA'] = 'MGHHHHHHMGGSTPWDSPSMAESFMRSFINGISSSGAFSGDQIGDMQDITGTMQASVEKMASTGRSSKSKLQAMNMAFASSMAEIAAAEAGGASMDSKTNAITDALRGAFLQTTGVSNEQFITEIRGLVSLIASNVNAGNSGRGQGGYGQGSGGNAAAIAAAIAAAIAAAGQGGQGGYGRQSQGAGSAAAAAAAAAAAAAAGSGQGGYGGQGQGGYGQSGSVTSGGYGYGTSAAAGAGVAAGSYAGAVNRLSSAEAASRVSSNIAAIASGGASALPSVISNIYSGVVASGVSSNEALIQALLELLSALVHVLSSASIGNVSSVGVDSTLNVVQDSVGQYVG'
        self._sequences['Br_MaSp2_300'] = self._sequences['NT'] + 'GGPGASAAVAVSSGPGGYGPGSPGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGSSAAVAVSSGPGGYGPGSQGGPSGPGSQGPSGPGGPGSSSAASGPGGYGPGSQGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGASAAVAVSSGPGGYGPGSQGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGASAAVAVSSGPGGYGPGSQGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGSSAAVAVSSGPGGYGPGSQGGPSGPGSQGPSG' + self._sequences['CT']
        self._sequences['Br_MaSp2_400'] = self._sequences['NT'] + 'GGPGASAAVAVSSGPGGYGPGSPGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGSSAAVAVSSGPGGYGPGSQGGPSGPGSQGPSGPGGPGSSSAASGPGGYGPGSQGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGASAAVAVSSGPGGYGPGSQGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGASAAVAVSSGPGGYGPGSQGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGSSAAVAVSSGPGGYGPGSQGGPSGPGSQGPSGPGGPGSSSAASGPGGYGPGSQGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGASAAVAVSSGPGGYGPGSQGPSGPSGPGGYGPGSQGGPS' + self._sequences['CT']
        self._sequences['Br_MaSp2_long'] = self._sequences['NT'] + 'GGPGASAAVAVSSGPGGYGPGSPGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGSSAAVAVSSGPGGYGPGSQGGPSGPGSQGPSGPGGPGSSSAASGPGGYGPGSQGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGASAAVAVSSGPGGYGPGSQGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGASAAVAVSSGPGGYGPGSQGP' + self._sequences['CT']
        self._sequences['Br_MaSp2_short'] = self._sequences['NT'] + 'SAASGPGGYGPGSQGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGASAAVAVSSGPGGYGPGSQGPSGPSGPGGYGPGSQGGPSGPGGYGPGSQGPNGPGGPGASAAVAVSSGPGGYGPGSQ' + self._sequences['CT']
        self._sequences['Br_MaSp4_long'] = self._sequences['NT'] + 'GFQGPGSSGGALTSYGTGPQGPSRPGSQGPSPQGPNGPRPQGPGSSVTVLTSYGPGPQGPSQQGPSTQVQTGTGPQDPALTNYAFSGPGSQGPSGPSSQQQSLQGQAGPQPQGPGSSVRILSYGLSQQGPSGPVPQGPSPQGPSVPGPQGPGSSVSISTSYKPGQQGPSGPSQQGPSTQVSNGPGHQAPALSTFAFSGPVPEASSGPSTQQPSFQGPARPRPQGPGS' + self._sequences['CT']
        self._sequences['Br_MaSp4_short'] = self._sequences['NT'] + 'GPSQQEPSTQGPTGPGPQAPALSTFAFSGPVPQGPSGPVPQGPSPQGPSVPGPQGPGSSVSISTSYKPDQQGPSGPSQQGPSTQVSNGPGPQAPALSTFAFSGPVPEASSGPSAQQPSFQGPAGPRPQGPGS' + self._sequences['CT']
        self._sequences['pV6E3'] = self._sequences['NT'] + 'GRGQGGYGEGSGGNVVVVVVGQGGQGGYGRESQGAGSVVVVVVGSGEGGYGGQGQGGYGQ' + self._sequences['CT']
        self._sequences['b16-2Rep'] = self._sequences['NT'] + 'GRGQGGYGQGSGGNALEAKLAALEAKLAGQGGQGGYGRQSQGAGSALEAKLAALEAKLAGSGQGGYGGQGQGGYGQ' + self._sequences['CT']

        # Load model and tokenizer
        self._tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
        self._model = AutoModel.from_pretrained(MODEL_NAME)
        self._model.eval()  # set to evaluation mode

        # Move model to GPU if available
        self._device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self._model.to(self._device)

    def get_embedding(self, sequence: str) -> None:
        """
        Compute the mean-pooled embedding of a protein sequence using ESM-2.
        """
        with torch.no_grad():
            tokens = self._tokenizer(sequence, return_tensors="pt")
            tokens = {k: v.to(self._device) for k, v in tokens.items()}
            outputs = self._model(**tokens)
            token_embeddings = outputs.last_hidden_state.squeeze(0)  # shape: (seq_len, hidden_dim)
            attention_mask = tokens["attention_mask"].squeeze(0)

            # Mean-pooling over valid tokens (ignoring padding)
            valid_embeddings = token_embeddings[attention_mask.bool()]
            sequence_embedding = valid_embeddings.mean(dim=0).cpu().numpy()
        return sequence_embedding

    def get_embeddings(self, save_embeddings: bool=True) -> pd.DataFrame:
        # Generate embeddings
        embedding_dict = {}
        for name, seq in tqdm(self._sequences.items(), desc="Embedding sequences", total=len(self._sequences)):
            try:
                embedding = self.get_embedding(seq)
                embedding_dict[name] = embedding
            except Exception as e:
                print(f"Failed to embed {name}: {e}")

        # Convert to DataFrame
        embedding_df = pd.DataFrame.from_dict(embedding_dict, orient="index")
        embedding_df.index.name = "Protein"
        embedding_df.reset_index(inplace=True)

        prots = ['A3IA', 'NT2RepCT', 'A3IA', 'A3IA', 'A3IA', 'NT2RepCT', 'A3IA', 'A3IA', 'A3IA', 'A3IA', 'NT2RepCT', 'NT2RepCT', 'NT2RepCT']
        prots_copies = ['50% Mcherry -A3IA, 50% A3IA', 'NT2RepCT 0.1% MCherry', 'A3I-A +0.1% Carbon Black', '25% Mcherry -A3IA, 75% A3IA', '12.5% Mcherry -A3IA, 87.5% A3IA', 'NT2RepCT + 50 uM Tht', 'A3IA 1 mM Imidazol', 'Mcherry -A3IA', 'A3IA 10 mM Imidazol', 'A3IA + 0.3% AcZ', 'NT2RepCT -Magnetic nanoparticles', 'NT2RepCT 0.1% Bri2MCherry', 'NT2RepCT 0.5% Bri2MCherry']
        for prot, prot_copy in zip(prots, prots_copies):
            ind = int(np.where(embedding_df.loc[:, 'Protein'] == prot)[0][0])
            embedding_df.loc[len(embedding_df)] = embedding_df.loc[ind]
            embedding_df.loc[len(embedding_df) - 1, 'Protein'] = prot_copy

        prots_combos = [('Rep7', 'NT2RepCT'), ('Rep7', 'NT2RepCT'), ('IdeS-A3IA', 'A3IA'), ('VN-NT', 'A3IA')]
        prots_new = ['Rep7 Tusp (30%) & NT2RepCT (70%)', 'Rep7 Tusp (57%) & NT2repCT (43%)', '20% IdeS-A3IA, 80% A3I_A', '5% VN-NT & A3IA']
        fracs = [(.3, .7), (.57, .43), (.2, .8), (.05, .95)]
        for prots, prot_new, fracs in zip(prots_combos, prots_new, fracs):
            inds = [int(np.where(embedding_df.loc[:, 'Protein'] == prot)[0][0]) for prot in prots]
            embedding_df.loc[len(embedding_df)] = 0
            embedding_df.loc[len(embedding_df) - 1, 'Protein'] = prot_new
            embedding_df.iloc[len(embedding_df) - 1, 1:] = fracs[0]*embedding_df.iloc[inds[0], 1:] + fracs[1]*embedding_df.iloc[inds[1], 1:]

        if save_embeddings:
            embedding_df.to_csv(os.path.join(os.pardir, 'data', 'protein_embeddings.csv'), index=False)
        return embedding_df

def pca(embedding_df: pd.DataFrame, save_embeddings: bool=True) -> pd.DataFrame:
    # Drop the protein identifier column (first column) to extract only numeric data
    X = embedding_df.drop(columns=["Protein"])

    # Standardize the data before PCA (important for PCA to work properly)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Apply PCA
    n_components = 15  # you can change this to 10â€“20 as discussed
    pca = PCA(n_components=n_components)
    X_pca = pca.fit_transform(X_scaled)

    # Create a new DataFrame with PCA components
    pca_columns = [f"pca_{i+1}" for i in range(n_components)]
    pca_df = pd.DataFrame(X_pca, columns=pca_columns)
    pca_df.insert(loc=0, column="Protein", value=embedding_df["Protein"].to_numpy())

    # Optional: Save or inspect
    if save_embeddings:
        pca_df.to_csv(os.path.join(os.pardir, 'data', 'protein_embeddings_pca.csv'), index=False)
    return pca_df


if __name__ == '__main__':
    MODEL_NAMES = ["facebook/esm2_t6_8M_UR50D",
                "facebook/esm2_t12_35M_UR50D",
                "facebook/esm2_t30_150M_UR50D",
                "facebook/esm2_t33_650M_UR50D",
                "facebook/esm2_t36_3B_UR50D",
                "facebook/esm2_t48_15B_UR50D"]
    MODEL_NAME = MODEL_NAMES[2]
    embedding_gen = EmbeddingGenerator(MODEL_NAME)
    embedding_df = embedding_gen.get_embeddings()
    pca_df = pca(embedding_df)